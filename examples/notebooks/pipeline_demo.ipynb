{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d0d1964ecce646",
   "metadata": {},
   "source": [
    "# Basic CTD Processing Pipeline Demo\n",
    "\n",
    "This notebook will provide an example of basic pipeline functionality using CTD processing as the subject. It is extremely uncommon to collect glider data without CTD measurements so generally, this processing can be applied to almost any glider.\n",
    "\n",
    "The data used here can be found at the [BOCD Bio-Carbon Deployment Catalogue](https://platforms.bodc.ac.uk/deployment-catalogue/BIO-Carbon/) under [Nelson (unit_397) OG NetCDF](https://linkedsystems.uk/erddap/files/Public_OG1_Data_001/Nelson_20240528/Nelson_646_R.nc). Context for the deployment can be found on the download site, but for further detail see the [NOC BIO-Carbon Project Page](https://noc.ac.uk/projects/bio-carbon).\n",
    "\n",
    "Once you have downloaded the data, it should be placed in the **examples/data/OG1** folder or, alternatively, you can edit the config for this notebook (**examples/configs/example_config_nelson.yaml**) so that \"file_path\" in the \"Load OG1\" step points towards where your data is stored.\n",
    "\n",
    "Alternatively, run the next cell to check for the datafile and download it if not present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d6a97-911c-40a9-b17b-e8c390cabfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "input_dir = Path(\"../data/OG1\")\n",
    "input_file = input_dir / \"Nelson_646_R.nc\"\n",
    "if not input_dir.exists():\n",
    "    input_dir.mkdir(parents=True)\n",
    "if not input_file.exists():\n",
    "    import requests\n",
    "    response = requests.get(\"https://linkedsystems.uk/erddap/files/Public_OG1_Data_001/Nelson_20240528/Nelson_646_R.nc\")\n",
    "    if response.status_code == 200:\n",
    "        with open(input_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Example file downloaded and written to {input_dir.resolve()}\")\n",
    "    else:\n",
    "        print(\"File download failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec538a996e5d28f",
   "metadata": {},
   "source": [
    "## Viewing the data\n",
    "\n",
    "This isn't necessary for the pipeline to work, however it is useful to see that data for those who are unfamiliar with glider data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b80cc80218a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "dataset = xr.load_dataset(\"../data/OG1/Nelson_646_R.nc\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59def7360025a7da",
   "metadata": {},
   "source": [
    "Feel free to explore the data variables in this dataset. Many will be completely filled with Nans, but for our purposes we only care about TIME, LATITUDE, LONGITUDE, PRES (pressure), CNDC (conductivity), and TEMP (temperature). You may notice that this data has not coordinates, which means it does not conform to the glider-community [OG1 format](https://github.com/OceanGlidersCommunity/OG-format-user-manual/blob/main/OG_Format.adoc) however, it is still compatable with the pipeline so long as the N_MEASUREMENTS dimension exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85096533ac557505",
   "metadata": {},
   "source": [
    "## Importing the pipeline\n",
    "\n",
    "Before anything can be run, we need to make sure that the necessary packages are installed. All of the requirements are listed in **requirements.txt** and can be installed automatically using `pip install -r requirements.txt` in a terminal (if using anaconda, make sure that you have selected the right environment using `conda activate your_env_name`). If you are missing any packages the pipeline may break.\n",
    "\n",
    "When we import the pipeline it will try and register all of the steps available to it. This is labeled as [Discovery] in the print log. If you are missing a package requirement, you will see a print in the form \"Failed to import <step>: <error message>\" which should indicate which package you are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166e73e4db22d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory and import the pipeline\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(f\"{cwd}/../../src\")\n",
    "from toolbox.pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d897e4efbcfb286",
   "metadata": {},
   "source": [
    "## Making the pipeline\n",
    "\n",
    "To make the pipeline, we simply have to make an instance using the `Pipeline()` class, passing it the path to the config which defines how we want to process the data. You should see a series of print logs indicating that the steps specified in the config have been found and added to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b461d67299389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline using the specified config\n",
    "Pipe = Pipeline(\n",
    "    config_path=r\"../examples/configs/example_config_nelson.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f6186292d0699",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "Calling the Pipeline.run() method tells the pipeline to execute all of the steps listed in the config in order from top-down. As it is running, it will plot diagnostics for steps where the setting is True. For more details on what is being run, see the comments in the config. Once completed, the processing has been excecuted and your data should be saved as **Nelson_646_R_Processed.nc** in the data/OG1 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbcd48681453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "Pipe.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a2c97c6334291",
   "metadata": {},
   "source": [
    "# Checking the output\n",
    "\n",
    "Because our pipeline \"Pipe\" is stored in pythons local variable space we can actually access the data without having to load in the processed data as we did for the input data. This can be done by looking in the pipeline context as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711210eacea9b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Pipe._context[\"data\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796608e58bcc9e2",
   "metadata": {},
   "source": [
    "If you compare the number of data variables here to that of the input data, we have gained 30 variables - these will be a mixture of our derived variables and new QC columns.\n",
    "\n",
    "I'd recommend checking the data with some plotting to make sure everything looks ok - in fact, with this dataset not everything is ok with the input CTD variables. If you look at the salinity outputs, they are much smaller than expected. This is because the CNDC input to the pipline was in the wrong units for the gsw-python implementation of the equation of state of seawater. This kind of error would have to be rectified manually by modifying the input data as the pipeline expects correct unit inputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
