# This file is part of the NOC Autonomy Toolbox.
#
# Copyright 2025-2026 National Oceanography Centre and The Contributors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Pipeline Configuration
pipeline:
  name: Example CTD Processing Pipeline
  description: A pipeline for processing CTD data
  visualisation: false

# Steps in the pipeline
# For further details on step parameters, see all_step_configs.yaml
# ----------------------- IMPORT DATA -----------------------
steps:
  - name: Load OG1
    parameters:
      file_path: ../examples/data/OG1/Nelson_646_R.nc # Path to the input NetCDF file
    diagnostics: false

# ----------------- BASIC QC + INTERPOLATION ----------------

# First, we apply basic testing on the coordinated varibales LATITUDE, LONGITUDE & TIME.
  - name: Apply QC
    parameters:
      qc_settings:
        impossible date test: {}  # Is the date is between 1985 and now?
        impossible location test: {} # Are the GPS coords within logical bounds?
        position on land test: {} # Are the coords on land?
        impossible speed test: {} # Is the horizontal speed reasonable?
    diagnostics: true # Plot all test outcomes

# Next we will apply QC to the CTD variables. Technically this step can be merged with
# the previous into a single Apply QC step, but here they are sepparate to make things
# more clear.
  - name: Apply QC
    parameters:
      qc_settings:

        range test: # Checks for bad data within a given range
          variable_ranges:
            PRES:
              3: [-5, -2.4] # Pressure in this range is flagged as probably bad (3)
              4: [-.inf, -5] # and bad (4) in this range.
          also_flag:
            # This takes the flags from pressure, and applies them to CNDC & TEMP as well.
            # ie. If PRES is bad, then CNDC & TEMP are probably also bad given it is all
            # from the same instrument.
            PRES: [CNDC, TEMP]
          plot: [PRES] # Plot pressure coloured by flag number

        stuck value test: # Checks for consecutive same values
          variables:
            PRES: 2 # If pressure is stuck for >2 values, they are flagged as bad
          also_flag:
            PRES: [CNDC, TEMP] # Apply the bad flags to CNDC & TEMP too
          plot: [PRES] # Plot the outcome for just pressure
    diagnostics: true

# Since we are using near-realtime data there are a lot of missing values. Also, since
# the GPS and science measurement clocks do not sample at the same rate, there are many
# points that have a CTD measurement but nans for GPS location. Since we need both to
# process CTD, we need to intepolate to fill in the missing data.
  - name: Interpolate Data
    parameters:
      qc_handling_settings:
        # This QC filtering functionality can be specified in most processing steps by
        # adding the qc_handling_settings parameter. Here we are using it to nan-out bad (4)
        # probably bad (3) and missing (9) data so that it can be interpolated over.
        flag_filter_settings:
          PRES: [3, 4, 9]
          LATITUDE: [3, 4, 9]
          LONGITUDE: [3, 4, 9]
        reconstruction_behaviour: replace
        flag_mapping: # The QC flags where bad data has been replaced turn into 8 (interpolated)
          3: 8
          4: 8
          9: 8
    diagnostics: true # Plot the outcome after interpolation

# --------------------- PROFILE FINDING ---------------------
# We now use the derive CTD step to add the DEPTH variable to the dataset as it
# is needed for profiling.
  - name: Derive CTD
    parameters:
      to_derive: [DEPTH]
    diagnostics: false

# Now we assign profile numbers
  - name: Find Profiles
    parameters:
      qc_handling_settings:
        # Again we are using QC filtering, this time to remove bad DEPTH data. You may
        # have noticed that we never explicitly tested DEPTH with Apply QC. Instead,
        # it has inherited QC via a combination of its parent variables QC, PRES & LATITUDE.
        flag_filter_settings:
          DEPTH: [3, 4, 9]
      gradient_thresholds: [0.033, -0.033] # Cutoffs for defining minimum velocity for up & downcasts
      filter_window_sizes: [20s, 20s] # Window sizes for median & mean smoothing
      depth_column: DEPTH
    diagnostics: true # When true, this step plots an interacive window that allows parameter adjustment.

# Now that profiles have been determined we should flag any that are too short or lack data at depth
  - name: Apply QC
    parameters:
      qc_settings:
          valid profile test:
            profile_length: 50 # Profiles must be at least 100 points long
            depth_range: [-1000, 0] # and must contain data within 0 and 1000 m
    diagnostics: true

# Finally we add profile direction to the dataset. +1 is ascending and -1 is descending
  - name: Find Profile Direction
    parameters:
    diagnostics: true

# ------------------ SALINITY ADJUSTMENT --------------------
# Now we move onto adjustment of the CNDC variable and subsequent salinity derivations
  - name: Salinity Adjustment
    parameters:
      qc_handling_settings:
        flag_filter_settings: # Filter out bad PROFILE_NUMBER, TEMP & CNDC data
          CNDC: [3, 4, 9]
          TEMP: [3, 4, 9]
          PROFILE_NUMBER: [3, 4, 9]
        reconstruction_behaviour: reinsert # The bad data will be added back in after processing
        flag_mapping: # The data that goes through adjustment will be reflagged as processed (5)
          0: 5
          1: 5
          2: 5
      filter_window_size: 21
      plot_profiles_in_range: [100, 150] # plot profiles 100 through to 150
    diagnostics: true

# Finally, derive the remaining CTD variables using another call of Derive CTD
  - name: Derive CTD
    parameters:
      to_derive: [
        PRAC_SALINITY,
        ABS_SALINITY,
        CONS_TEMP,
        DENSITY
      ]
    diagnostics: false

# ---------------------- EXPORT DATA ------------------------
# Exporting the output data to the same folder as the input data
  - name: "Data Export"
    parameters:
      export_format: "netcdf"
      output_path: "../examples/data/OG1/Nelson_646_R_Processed.nc"